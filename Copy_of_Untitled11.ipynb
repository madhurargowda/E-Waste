{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WsfQppQqR32w"
      },
      "outputs": [],
      "source": [
        "# üì¶ Import essential libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# üìÇ For Google Drive access\n",
        "\n",
        "\n",
        "# üñºÔ∏è Image Processing & Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# üî• Deep Learning (Keras + TensorFlow)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# üé≠ Classification Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# üì¶ Handling ZIP Files\n",
        "import zipfile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "73iIAutrSdrl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset found: ['1.txt', '10.txt', '11.txt', '12.txt', '13.txt', '14.txt', '15.txt', '151.txt', '152.txt', '153.jpg', '153.txt', '154.jpg', '154.txt', '155.jpg', '155.txt', '156.jpg', '156.txt', '157.jpg', '157.txt', '158.jpg', '158.txt', '159.jpg', '159.txt', '16.txt', '160.jpg', '160.txt', '161.jpg', '161.txt', '162.jpg', '162.txt', '163.jpg', '163.txt', '164.txt', '165.jpg', '165.txt', '166.txt', '167.jpg', '167.txt', '168.txt', '169.jpg', '169.txt', '17.txt', '170.txt', '171.jpg', '171.txt', '172.txt', '173.jpg', '173.txt', '174.txt', '175.jpg', '175.txt', '176.txt', '177.jpg', '177.txt', '178.txt', '179.jpg', '179.txt', '18.txt', '180.jpg', '180.txt', '181.txt', '182.txt', '183.txt', '184.txt', '185.txt', '186.txt', '187.txt', '188.txt', '189.txt', '19.txt', '190.txt', '191.txt', '192.txt', '193.txt', '194.txt', '195.txt', '196.txt', '197.txt', '198.txt', '199.txt', '2.txt', '20.txt', '200.txt', '202.txt', '203.txt', '204.txt', '205.txt', '206.txt', '207.txt', '208.txt', '209.txt', '21.txt', '210.jpg', '210.txt', '211.jpg', '211.txt', '212.txt', '213.txt', '214.txt', '215.txt', '216.txt', '217.txt', '22.txt', '23.txt', '230.txt', '231.txt', '232.txt', '233.txt', '235.txt', '236.txt', '237.txt', '238.txt', '239.txt', '24.txt', '240.txt', '241.txt', '242.txt', '243.txt', '244.jpg', '244.txt', '245.jpg', '245.txt', '246.jpg', '246.txt', '247.jpg', '247.txt', '248.jpg', '248.txt', '249.jpg', '249.txt', '25.txt', '250.txt', '251.txt', '252.txt', '253.txt', '254.txt', '255.txt', '256.txt', '257.txt', '258.txt', '259.txt', '26.txt', '261.txt', '262.txt', '263.txt', '264.txt', '265.txt', '266.txt', '267.txt', '268.txt', '269.txt', '27.txt', '28.txt', '29.txt', '3.txt', '30.txt', '301.txt', '302.txt', '303.txt', '304.txt', '305.jpg', '305.txt', '306.jpg', '306.txt', '307.jpg', '307.txt', '308.txt', '309.txt', '31.txt', '310.txt', '311.txt', '313.txt', '314.txt', '315.txt', '316.txt', '317.txt', '318.txt', '319.txt', '32.txt', '320.txt', '321.txt', '322.txt', '323.txt', '324.txt', '325.txt', '326.txt', '327.txt', '328.txt', '329.txt', '33.txt', '330.txt', '331.txt', '332.txt', '333.txt', '334.txt', '335.txt', '336.txt', '337.txt', '338.txt', '339.txt', '34.txt', '340.txt', '341.txt', '342.txt', '343.txt', '344.txt', '345.txt', '346.txt', '35.txt', '4.txt', '451.txt', '452.txt', '453.txt', '454.txt', '455.txt', '456.txt', '457.txt', '458.txt', '459.txt', '460.txt', '461.txt', '462.txt', '463.txt', '464.txt', '465.txt', '466.txt', '467.txt', '468.txt', '469.txt', '470.txt', '471.txt', '472.txt', '473.jpg', '473.txt', '474.jpg', '474.txt', '475.jpg', '475.txt', '476.jpg', '476.txt', '477.jpg', '477.txt', '478.jpg', '478.txt', '479.jpg', '479.txt', '480.jpg', '480.txt', '481.jpg', '481.txt', '482.jpg', '482.txt', '483.jpg', '483.txt', '484.jpg', '484.txt', '485.jpg', '485.txt', '486.jpg', '486.txt', '487.txt', '488.txt', '489.txt', '490.txt', '491.txt', '492.txt', '493.txt', '494.txt', '495.txt', '496.txt', '497.txt', '498.txt', '499.txt', '5.jpg', '5.txt', '500.txt', '501.txt', '502.txt', '503.txt', '504.txt', '505.txt', '506.txt', '507.txt', '508.txt', '509.txt', '510.txt', '511.txt', '512.txt', '513.jpg', '513.txt', '514.jpg', '514.txt', '515.jpg', '515.txt', '516.jpg', '516.txt', '517.jpg', '517.txt', '518.jpg', '518.txt', '519.txt', '520.txt', '521.txt', '522.txt', '523.txt', '524.txt', '525.txt', '526.txt', '527.txt', '528.txt', '530.txt', '531.txt', '532.txt', '533.txt', '534.txt', '535.txt', '536.txt', '537.txt', '538.txt', '539.txt', '540.txt', '541.txt', '542.txt', '543.txt', '544.txt', '545.txt', '546.txt', '547.txt', '548.txt', '549.txt', '550.jpg', '550.txt', '551.jpg', '551.txt', '552.jpg', '552.txt', '553.jpg', '553.txt', '554.jpg', '554.txt', '555.jpg', '555.txt', '556.jpg', '556.txt', '557.jpg', '557.txt', '558.jpg', '558.txt', '559.jpg', '559.txt', '560.jpg', '560.txt', '561.jpg', '561.txt', '562.jpg', '562.txt', '563.jpg', '563.txt', '564.jpg', '564.txt', '565.jpg', '565.txt', '566.jpg', '566.txt', '567.jpg', '567.txt', '568.jpg', '568.txt', '569.jpg', '569.txt', '570.jpg', '570.txt', '571.jpg', '571.txt', '572.jpg', '572.txt', '573.jpg', '573.txt', '574.txt', '575.txt', '576.txt', '577.txt', '578.txt', '579.txt', '580.txt', '581.txt', '582.txt', '583.txt', '584.txt', '585.txt', '586.txt', '587.txt', '588.txt', '589.txt', '590.txt', '591.txt', '592.txt', '593.txt', '594.txt', '595.txt', '596.txt', '597.txt', '598.txt', '599.txt', '6.txt', '600.txt', '601.txt', '602.txt', '603.txt', '604.txt', '605.txt', '606.txt', '607.txt', '608.txt', '609.txt', '610.txt', '611.txt', '612.txt', '613.txt', '614.jpg', '614.txt', '615.jpg', '615.txt', '616.txt', '617.txt', '618.txt', '619.txt', '620.txt', '621.txt', '622.txt', '623.txt', '624.txt', '625.txt', '626.txt', '627(1).txt', '627.txt', '628(1).txt', '628.txt', '629(1).txt', '629.txt', '630(1).txt', '630.txt', '631.txt', '632.txt', '633.txt', '634.txt', '635(1).txt', '635.txt', '636.txt', '637.txt', '7.txt', '751.txt', '752.txt', '753.jpg', '753.txt', '754.txt', '755.jpg', '755.txt', '756.jpg', '756.txt', '757.jpg', '757.txt', '758.jpg', '758.txt', '759.jpg', '759.txt', '760.txt', '761.txt', '762.txt', '763.txt', '764.txt', '765.txt', '766.txt', '767.txt', '768.txt', '769.jpg', '769.txt', '770.txt', '771.txt', '772.txt', '773.txt', '774.txt', '775.txt', '776.txt', '777.txt', '778.txt', '779.txt', '780.txt', '781.txt', '782.txt', '783.txt', '784.txt', '785.txt', '786.txt', '787.txt', '788.txt', '789.jpg', '789.txt', '790.jpg', '790.txt', '791.jpg', '791.txt', '792.txt', '793.txt', '794.txt', '795.txt', '796.txt', '797.txt', '798.txt', '799.txt', '8.txt', '800.txt', '801.txt', '802.txt', '803.txt', '807.txt', '808.txt', '809.txt', '810.txt', '811.txt', '812.txt', '813.txt', '814.txt', '815.txt', '816.txt', '9.jpg', '9.txt', '901.txt', '902.txt', '903.txt', 'abc.jpg', 'abc.txt', 'Copy of IMG_20200328_131938.jpg', 'Copy of IMG_20200328_131938.txt', 'Copy of IMG_20200328_131942.jpg', 'Copy of IMG_20200328_131942.txt', 'Copy of IMG_20200328_131944.jpg', 'Copy of IMG_20200328_131944.txt', 'Copy of IMG_20200328_131952.jpg', 'Copy of IMG_20200328_131952.txt', 'Copy of IMG_20200328_131958.jpg', 'Copy of IMG_20200328_131958.txt', 'Copy of IMG_20200328_132000.jpg', 'Copy of IMG_20200328_132000.txt', 'Copy of IMG_20200328_132038.jpg', 'Copy of IMG_20200328_132038.txt', 'Copy of IMG_20200328_132051.jpg', 'Copy of IMG_20200328_132051.txt', 'Copy of IMG_20200328_132109.jpg', 'Copy of IMG_20200328_132109.txt', 'Copy of IMG_20200328_132116.jpg', 'Copy of IMG_20200328_132116.txt', 'Copy of IMG_20200328_132119.jpg', 'Copy of IMG_20200328_132119.txt', 'Copy of IMG_20200328_132120.jpg', 'Copy of IMG_20200328_132120.txt', 'Copy of IMG_20200328_132124.jpg', 'Copy of IMG_20200328_132124.txt', 'Copy of IMG_20200328_132129.jpg', 'Copy of IMG_20200328_132129.txt', 'Copy of IMG_20200328_132131.jpg', 'Copy of IMG_20200328_132131.txt', 'Copy of IMG_20200328_132135.jpg', 'Copy of IMG_20200328_132135.txt', 'Copy of IMG_20200328_132149.jpg', 'Copy of IMG_20200328_132149.txt', 'Copy of IMG_20200328_132151.jpg', 'Copy of IMG_20200328_132151.txt', 'Copy of IMG_20200328_132156.jpg', 'Copy of IMG_20200328_132156.txt', 'Copy of IMG_20200328_134825.jpg', 'Copy of IMG_20200328_134825.txt', 'Copy of IMG_20200328_134847.jpg', 'Copy of IMG_20200328_134847.txt', 'Copy of IMG_20200328_134852.jpg', 'Copy of IMG_20200328_134852.txt', 'Copy of IMG_20200328_134903.jpg', 'Copy of IMG_20200328_134903.txt', 'Copy of IMG_20200328_134906.jpg', 'Copy of IMG_20200328_134906.txt', 'Copy of IMG_20200328_135222.jpg', 'Copy of IMG_20200328_135222.txt', 'Copy of IMG_20200328_135224.jpg', 'Copy of IMG_20200328_135224.txt', 'Copy of IMG_20200328_135230.jpg', 'Copy of IMG_20200328_135230.txt', 'Copy of IMG_20200328_135237.jpg', 'Copy of IMG_20200328_135237.txt', 'Copy of IMG_20200328_135240.jpg', 'Copy of IMG_20200328_135240.txt', 'Copy of IMG_20200328_135302.jpg', 'Copy of IMG_20200328_135302.txt', 'Copy of IMG_20200328_135306.jpg', 'Copy of IMG_20200328_135306.txt', 'Copy of IMG_20200328_135312.jpg', 'Copy of IMG_20200328_135312.txt', 'Copy of IMG_20200328_135435.jpg', 'Copy of IMG_20200328_135435.txt', 'Copy of IMG_20200328_135457.jpg', 'Copy of IMG_20200328_135457.txt', 'Copy of IMG_20200328_135503.jpg', 'Copy of IMG_20200328_135503.txt', 'Copy of IMG_20200328_135507.jpg', 'Copy of IMG_20200328_135507.txt', 'Copy of IMG_20200328_135512.jpg', 'Copy of IMG_20200328_135512.txt', 'Copy of IMG_20200328_140053.jpg', 'Copy of IMG_20200328_140053.txt', 'Copy of IMG_20200328_140056.jpg', 'Copy of IMG_20200328_140056.txt', 'Copy of IMG_20200328_140104.jpg', 'Copy of IMG_20200328_140104.txt', 'Copy of IMG_20200328_140107.jpg', 'Copy of IMG_20200328_140107.txt', 'Copy of IMG_20200328_140109.jpg', 'Copy of IMG_20200328_140109.txt', 'Copy of IMG_20200328_140112.jpg', 'Copy of IMG_20200328_140112.txt', 'Copy of IMG_20200328_140115.jpg', 'Copy of IMG_20200328_140115.txt', 'Copy of IMG_20200328_140117.jpg', 'Copy of IMG_20200328_140117.txt', 'Copy of IMG_20200328_140124.jpg', 'Copy of IMG_20200328_140124.txt', 'Copy of IMG_20200328_214915.jpg', 'Copy of IMG_20200328_214915.txt', 'Copy of IMG_20200328_214955.jpg', 'Copy of IMG_20200328_214955.txt', 'Copy of IMG_20200328_215002.jpg', 'Copy of IMG_20200328_215002.txt', 'Copy of IMG_20200328_215102.jpg', 'Copy of IMG_20200328_215102.txt', 'Copy of IMG_20200328_215107.jpg', 'Copy of IMG_20200328_215107.txt', 'Copy of IMG_20200328_215110.jpg', 'Copy of IMG_20200328_215110.txt', 'Copy of IMG_20200328_215118.jpg', 'Copy of IMG_20200328_215118.txt', 'Copy of IMG_20200328_221548.jpg', 'Copy of IMG_20200328_221548.txt', 'Copy of IMG_20200328_221604.jpg', 'Copy of IMG_20200328_221604.txt', 'Copy of IMG_20200328_221613.jpg', 'Copy of IMG_20200328_221613.txt', 'Copy of IMG_20200328_221622.jpg', 'Copy of IMG_20200328_221622.txt', 'Copy of IMG_20200328_221651.jpg', 'Copy of IMG_20200328_221651.txt', 'Copy of IMG_20200328_221706.jpg', 'Copy of IMG_20200328_221706.txt', 'Copy of IMG_20200328_221715.jpg', 'Copy of IMG_20200328_221715.txt', 'Copy of IMG_20200328_222043.jpg', 'Copy of IMG_20200328_222043.txt', 'Copy of IMG_20200328_222053.jpg', 'Copy of IMG_20200328_222053.txt', 'Copy of IMG_20200328_222058.jpg', 'Copy of IMG_20200328_222058.txt', 'Copy of IMG_20200328_222105.jpg', 'Copy of IMG_20200328_222105.txt', 'Copy of IMG_20200328_222123.jpg', 'Copy of IMG_20200328_222123.txt', 'dataset_labels.csv', 'IMG-20200328-WA0024.jpg', 'IMG-20200328-WA0024.txt', 'IMG-20200328-WA0025.jpg', 'IMG-20200328-WA0025.txt', 'IMG-20200328-WA0026.jpg', 'IMG-20200328-WA0026.txt', 'IMG-20200328-WA0027.jpg', 'IMG-20200328-WA0027.txt', 'IMG-20200328-WA0028.jpg', 'IMG-20200328-WA0028.txt', 'IMG-20200328-WA0029.jpg', 'IMG-20200328-WA0029.txt', 'IMG-20200328-WA0030(1).jpg', 'IMG-20200328-WA0030(1).txt', 'IMG-20200328-WA0030.jpg', 'IMG-20200328-WA0030.txt', 'IMG-20200328-WA0031.jpg', 'IMG-20200328-WA0031.txt', 'IMG-20200328-WA0032.jpg', 'IMG-20200328-WA0032.txt', 'IMG-20200328-WA0033.jpg', 'IMG-20200328-WA0033.txt', 'IMG-20200328-WA0034.jpg', 'IMG-20200328-WA0034.txt', 'IMG-20200328-WA0037.jpg', 'IMG-20200328-WA0037.txt', 'IMG-20200328-WA0039.jpg', 'IMG-20200328-WA0039.txt', 'IMG-20200328-WA0040.jpg', 'IMG-20200328-WA0040.txt', 'IMG-20200328-WA0041.jpg', 'IMG-20200328-WA0041.txt', 'IMG-20200328-WA0042.jpg', 'IMG-20200328-WA0042.txt', 'IMG-20200328-WA0043.jpg', 'IMG-20200328-WA0043.txt', 'IMG-20200328-WA0044.jpg', 'IMG-20200328-WA0044.txt', 'IMG-20200328-WA0045.jpg', 'IMG-20200328-WA0045.txt', 'IMG-20200328-WA0046.jpg', 'IMG-20200328-WA0046.txt', 'IMG-20200328-WA0047.jpg', 'IMG-20200328-WA0047.txt', 'IMG-20200328-WA0048(1).jpg', 'IMG-20200328-WA0048(1).txt', 'IMG-20200328-WA0049.jpg', 'IMG-20200328-WA0049.txt', 'IMG-20200329-WA0066.jpg', 'IMG-20200329-WA0066.txt', 'IMG-20200329-WA0067.jpg', 'IMG-20200329-WA0067.txt', 'IMG-20200329-WA0068.jpg', 'IMG-20200329-WA0068.txt', 'IMG-20200329-WA0069.jpg', 'IMG-20200329-WA0069.txt', 'IMG-20200329-WA0070.jpg', 'IMG-20200329-WA0070.txt', 'IMG-20200329-WA0071.jpg', 'IMG-20200329-WA0071.txt', 'IMG-20200329-WA0072.jpg', 'IMG-20200329-WA0072.txt', 'IMG-20200329-WA0073.jpg', 'IMG-20200329-WA0073.txt', 'IMG-20200329-WA0074.jpg', 'IMG-20200329-WA0074.txt', 'IMG-20200329-WA0075.jpg', 'IMG-20200329-WA0075.txt', 'IMG-20200329-WA0076.jpg', 'IMG-20200329-WA0076.txt', 'IMG-20200329-WA0077.jpg', 'IMG-20200329-WA0077.txt', 'IMG-20200329-WA0078.jpg', 'IMG-20200329-WA0078.txt', 'IMG_20190211_195144.jpg', 'IMG_20190211_195144.txt', 'IMG_20190211_195203.jpg', 'IMG_20190211_195203.txt', 'IMG_20190211_195304.jpg', 'IMG_20190211_195304.txt', 'IMG_20190211_195311.jpg', 'IMG_20190211_195311.txt', 'IMG_20190211_195323.jpg', 'IMG_20190211_195323.txt', 'IMG_20190211_195330.jpg', 'IMG_20190211_195330.txt', 'IMG_20190211_195336.jpg', 'IMG_20190211_195336.txt', 'IMG_20190211_195411.jpg', 'IMG_20190211_195411.txt', 'IMG_20190211_195417.jpg', 'IMG_20190211_195417.txt', 'IMG_20190211_195428.jpg', 'IMG_20190211_195428.txt', 'IMG_20190211_195437.jpg', 'IMG_20190211_195437.txt', 'IMG_20190211_195440.jpg', 'IMG_20190211_195440.txt', 'IMG_20190211_195445.jpg', 'IMG_20190211_195445.txt', 'IMG_20190211_195510.jpg', 'IMG_20190211_195510.txt', 'IMG_20190211_195517.jpg', 'IMG_20190211_195517.txt', 'IMG_20190211_195528.jpg', 'IMG_20190211_195528.txt', 'IMG_20190211_195541.jpg', 'IMG_20190211_195541.txt', 'IMG_20190211_195619.jpg', 'IMG_20190211_195619.txt', 'IMG_20190211_195623.jpg', 'IMG_20190211_195623.txt', 'IMG_20190211_195640.jpg', 'IMG_20190211_195640.txt', 'IMG_20190211_195643.jpg', 'IMG_20190211_195643.txt', 'IMG_20190211_195653.jpg', 'IMG_20190211_195653.txt', 'IMG_20190211_195710.jpg', 'IMG_20190211_195710.txt', 'IMG_20190211_195740.jpg', 'IMG_20190211_195740.txt', 'IMG_20190211_195756.jpg', 'IMG_20190211_195756.txt', 'IMG_20190211_195804.jpg', 'IMG_20190211_195804.txt', 'IMG_20190211_195813.jpg', 'IMG_20190211_195813.txt', 'IMG_20190211_195818.jpg', 'IMG_20190211_195818.txt', 'IMG_20190211_195824.jpg', 'IMG_20190211_195824.txt', 'IMG_20190211_195829.jpg', 'IMG_20190211_195829.txt', 'IMG_20190211_195835.jpg', 'IMG_20190211_195835.txt', 'IMG_20190211_195842.jpg', 'IMG_20190211_195842.txt', 'IMG_20190211_211014.jpg', 'IMG_20190211_211014.txt', 'IMG_20190211_211021.jpg', 'IMG_20190211_211021.txt', 'IMG_20190211_211027.jpg', 'IMG_20190211_211027.txt', 'IMG_20190211_211033.jpg', 'IMG_20190211_211033.txt', 'IMG_20190211_211051.jpg', 'IMG_20190211_211051.txt', 'IMG_20190211_211103.jpg', 'IMG_20190211_211103.txt', 'IMG_20190211_211106.jpg', 'IMG_20190211_211106.txt', 'IMG_20190211_211118.jpg', 'IMG_20190211_211118.txt', 'IMG_20190211_211542.jpg', 'IMG_20190211_211542.txt', 'IMG_20190211_211549.jpg', 'IMG_20190211_211549.txt', 'IMG_20190211_211551.jpg', 'IMG_20190211_211551.txt', 'IMG_20190211_211553.jpg', 'IMG_20190211_211553.txt', 'IMG_20190211_211559.jpg', 'IMG_20190211_211559.txt', 'IMG_20190211_211605.jpg', 'IMG_20190211_211605.txt', 'IMG_20190211_211608.jpg', 'IMG_20190211_211608.txt', 'IMG_20190211_211612.jpg', 'IMG_20190211_211612.txt', 'IMG_20190211_211617.jpg', 'IMG_20190211_211617.txt', 'IMG_20190211_211620.jpg', 'IMG_20190211_211620.txt', 'IMG_20190211_211623.jpg', 'IMG_20190211_211623.txt', 'IMG_20190211_211635.jpg', 'IMG_20190211_211635.txt', 'IMG_20190211_211642.jpg', 'IMG_20190211_211642.txt', 'IMG_20190211_211654.jpg', 'IMG_20190211_211654.txt', 'IMG_20190211_211704.jpg', 'IMG_20190211_211704.txt', 'IMG_20190211_211706.jpg', 'IMG_20190211_211706.txt', 'IMG_20190211_211709.jpg', 'IMG_20190211_211709.txt', 'IMG_20190211_211711.jpg', 'IMG_20190211_211711.txt', 'IMG_20190211_211715.jpg', 'IMG_20190211_211715.txt', 'IMG_20190211_211717.jpg', 'IMG_20190211_211717.txt', 'IMG_20190211_211719.jpg', 'IMG_20190211_211719.txt', 'IMG_20190211_211724.jpg', 'IMG_20190211_211724.txt', 'IMG_20190211_211739.jpg', 'IMG_20190211_211739.txt', 'IMG_20190211_211743.jpg', 'IMG_20190211_211743.txt', 'IMG_20190211_211754.jpg', 'IMG_20190211_211754.txt', 'IMG_20190211_211757.jpg', 'IMG_20190211_211757.txt', 'IMG_20190211_211759.jpg', 'IMG_20190211_211759.txt', 'IMG_20190211_211802.jpg', 'IMG_20190211_211802.txt', 'IMG_20190211_211804.jpg', 'IMG_20190211_211804.txt', 'IMG_20190211_211807.jpg', 'IMG_20190211_211807.txt', 'IMG_20190211_211810.jpg', 'IMG_20190211_211810.txt', 'IMG_20190211_211819.jpg', 'IMG_20190211_211819.txt', 'IMG_20190211_211824.jpg', 'IMG_20190211_211824.txt', 'IMG_20190211_211835.jpg', 'IMG_20190211_211835.txt', 'IMG_20190211_211848.jpg', 'IMG_20190211_211848.txt', 'IMG_20190211_211850.jpg', 'IMG_20190211_211850.txt', 'IMG_20190211_211856.jpg', 'IMG_20190211_211856.txt', 'IMG_20190211_211907.jpg', 'IMG_20190211_211907.txt', 'IMG_20190211_211908.jpg', 'IMG_20190211_211908.txt', 'IMG_20190211_211909.jpg', 'IMG_20190211_211909.txt', 'IMG_20190211_211911.jpg', 'IMG_20190211_211911.txt', 'IMG_20190211_211913.jpg', 'IMG_20190211_211913.txt', 'IMG_20190211_211913_01.jpg', 'IMG_20190211_211913_01.txt', 'IMG_20190211_211920.jpg', 'IMG_20190211_211920.txt', 'IMG_20190211_211922.jpg', 'IMG_20190211_211922.txt', 'IMG_20190211_211924.jpg', 'IMG_20190211_211924.txt', 'IMG_20190211_211930.jpg', 'IMG_20190211_211930.txt', 'IMG_20190211_211933.jpg', 'IMG_20190211_211933.txt', 'IMG_20190211_211935.jpg', 'IMG_20190211_211935.txt', 'IMG_20190211_211941.jpg', 'IMG_20190211_211941.txt', 'IMG_20190211_212004.jpg', 'IMG_20190211_212004.txt', 'IMG_20190211_212009.jpg', 'IMG_20190211_212009.txt', 'IMG_20190211_212013.jpg', 'IMG_20190211_212013.txt', 'IMG_20190211_212015.jpg', 'IMG_20190211_212015.txt', 'IMG_20190211_212018.jpg', 'IMG_20190211_212018.txt', 'IMG_20190211_212114.jpg', 'IMG_20190211_212114.txt', 'IMG_20190211_212118.jpg', 'IMG_20190211_212118.txt', 'IMG_20190211_212124.jpg', 'IMG_20190211_212124.txt', 'IMG_20190211_212127.jpg', 'IMG_20190211_212127.txt', 'IMG_20190211_212130.jpg', 'IMG_20190211_212130.txt', 'IMG_20190212_213839.jpg', 'IMG_20190212_213839.txt', 'IMG_20190212_213851.jpg', 'IMG_20190212_213851.txt', 'IMG_20190212_213854.jpg', 'IMG_20190212_213854.txt', 'IMG_20190212_213913.jpg', 'IMG_20190212_213913.txt', 'IMG_20190212_213917.jpg', 'IMG_20190212_213917.txt', 'IMG_20190212_213920.jpg', 'IMG_20190212_213920.txt', 'IMG_20190212_213925.jpg', 'IMG_20190212_213925.txt', 'IMG_20190212_213929.jpg', 'IMG_20190212_213929.txt', 'IMG_20190212_213931.jpg', 'IMG_20190212_213931.txt', 'IMG_20190212_213935.jpg', 'IMG_20190212_213935.txt', 'IMG_20190212_214037.jpg', 'IMG_20190212_214037.txt', 'IMG_20190212_214043.jpg', 'IMG_20190212_214043.txt', 'IMG_20190212_214046.jpg', 'IMG_20190212_214046.txt', 'IMG_20190212_214051.jpg', 'IMG_20190212_214051.txt', 'IMG_20190212_214057.jpg', 'IMG_20190212_214057.txt', 'IMG_20190212_214104.jpg', 'IMG_20190212_214104.txt', 'IMG_20190212_214109.jpg', 'IMG_20190212_214109.txt', 'IMG_20190212_214113.jpg', 'IMG_20190212_214113.txt', 'IMG_20190212_214117.jpg', 'IMG_20190212_214117.txt', 'IMG_20190212_214120.jpg', 'IMG_20190212_214120.txt', 'IMG_20190212_214133.jpg', 'IMG_20190212_214133.txt', 'IMG_20190212_214136.jpg', 'IMG_20190212_214136.txt', 'IMG_20190212_214137.jpg', 'IMG_20190212_214137.txt', 'IMG_20190212_214141.jpg', 'IMG_20190212_214141.txt', 'IMG_20190212_214146.jpg', 'IMG_20190212_214146.txt', 'IMG_20190212_214151.jpg', 'IMG_20190212_214151.txt', 'IMG_20190212_214154.jpg', 'IMG_20190212_214154.txt', 'IMG_20190212_214158.jpg', 'IMG_20190212_214158.txt', 'IMG_20190212_214207.jpg', 'IMG_20190212_214207.txt', 'IMG_20190212_214211.jpg', 'IMG_20190212_214211.txt', 'IMG_20190212_214214.jpg', 'IMG_20190212_214214.txt', 'IMG_20190212_214218.jpg', 'IMG_20190212_214218.txt', 'IMG_20190212_214227.jpg', 'IMG_20190212_214227.txt', 'IMG_20190212_214231.jpg', 'IMG_20190212_214231.txt', 'IMG_20190212_214234.jpg', 'IMG_20190212_214234.txt', 'IMG_20190212_214240.jpg', 'IMG_20190212_214240.txt', 'IMG_20190212_214242.jpg', 'IMG_20190212_214242.txt', 'IMG_20190212_214259.jpg', 'IMG_20190212_214259.txt', 'IMG_20190212_214301.jpg', 'IMG_20190212_214301.txt', 'IMG_20190212_214303.jpg', 'IMG_20190212_214303.txt', 'IMG_20190212_214309.jpg', 'IMG_20190212_214309.txt', 'IMG_20190212_214311.jpg', 'IMG_20190212_214311.txt', 'IMG_20190212_214313.jpg', 'IMG_20190212_214313.txt', 'IMG_20190212_214315.jpg', 'IMG_20190212_214315.txt', 'IMG_20190212_214404.jpg', 'IMG_20190212_214404.txt', 'IMG_20190212_214405.jpg', 'IMG_20190212_214405.txt', 'IMG_20190212_214441.jpg', 'IMG_20190212_214441.txt', 'IMG_20190212_214446.jpg', 'IMG_20190212_214446.txt', 'IMG_20190212_214451.jpg', 'IMG_20190212_214451.txt', 'IMG_20190212_214452.jpg', 'IMG_20190212_214452.txt', 'IMG_20190212_214503.jpg', 'IMG_20190212_214503.txt', 'IMG_20190212_214507.jpg', 'IMG_20190212_214507.txt', 'IMG_20190212_214509.jpg', 'IMG_20190212_214509.txt', 'IMG_20190212_214514.jpg', 'IMG_20190212_214514.txt', 'IMG_20190212_214519.jpg', 'IMG_20190212_214519.txt', 'IMG_20190212_214523.jpg', 'IMG_20190212_214523.txt', 'IMG_20190212_214524.jpg', 'IMG_20190212_214524.txt', 'IMG_20190212_214529.jpg', 'IMG_20190212_214529.txt', 'IMG_20190212_214532.jpg', 'IMG_20190212_214532.txt', 'IMG_20190212_214541.jpg', 'IMG_20190212_214541.txt', 'IMG_20190212_214550.jpg', 'IMG_20190212_214550.txt', 'IMG_20190212_214558.jpg', 'IMG_20190212_214558.txt', 'IMG_20190212_214607.jpg', 'IMG_20190212_214607.txt', 'IMG_20190212_214612.jpg', 'IMG_20190212_214612.txt', 'IMG_20190212_214615.jpg', 'IMG_20190212_214615.txt', 'IMG_20190212_214617.jpg', 'IMG_20190212_214617.txt', 'IMG_20190212_214620.jpg', 'IMG_20190212_214620.txt', 'IMG_20190212_214628.jpg', 'IMG_20190212_214628.txt', 'IMG_20190212_214635.jpg', 'IMG_20190212_214635.txt', 'IMG_20190212_214641.jpg', 'IMG_20190212_214641.txt', 'IMG_20190212_214643.jpg', 'IMG_20190212_214643.txt', 'IMG_20190212_214652.jpg', 'IMG_20190212_214652.txt', 'IMG_20190212_214654.jpg', 'IMG_20190212_214654.txt', 'IMG_20190212_214702.jpg', 'IMG_20190212_214702.txt', 'IMG_20190212_214706.jpg', 'IMG_20190212_214706.txt', 'IMG_20190212_214710.jpg', 'IMG_20190212_214710.txt', 'IMG_20190212_214714.jpg', 'IMG_20190212_214714.txt', 'IMG_20190212_214717.jpg', 'IMG_20190212_214717.txt', 'IMG_20190212_214721.jpg', 'IMG_20190212_214721.txt', 'IMG_20190212_214728.jpg', 'IMG_20190212_214728.txt', 'IMG_20190212_214732.jpg', 'IMG_20190212_214732.txt', 'IMG_20200328_131159.jpg', 'IMG_20200328_131159.txt', 'IMG_20200328_131230.jpg', 'IMG_20200328_131230.txt', 'IMG_20200328_131236.jpg', 'IMG_20200328_131236.txt', 'IMG_20200328_131300.jpg', 'IMG_20200328_131300.txt', 'IMG_20200328_131316.jpg', 'IMG_20200328_131316.txt', 'IMG_20200328_131322.jpg', 'IMG_20200328_131322.txt', 'IMG_20200328_131329.jpg', 'IMG_20200328_131329.txt', 'IMG_20200328_131506.jpg', 'IMG_20200328_131506.txt', 'IMG_20200328_131510.jpg', 'IMG_20200328_131510.txt', 'IMG_20200328_131519.jpg', 'IMG_20200328_131519.txt', 'IMG_20200328_131600.jpg', 'IMG_20200328_131600.txt', 'IMG_20200328_131615.jpg', 'IMG_20200328_131615.txt', 'IMG_20200328_131708.jpg', 'IMG_20200328_131708.txt', 'IMG_20200328_131720.jpg', 'IMG_20200328_131720.txt', 'IMG_20200328_215102.jpg', 'IMG_20200328_215102.txt', 'IMG_20200328_215107.jpg', 'IMG_20200328_215107.txt', 'IMG_20200328_215110.jpg', 'IMG_20200328_215110.txt', 'IMG_20200329_142515.jpg', 'IMG_20200329_142515.txt', 'IMG_20200329_142521.jpg', 'IMG_20200329_142521.txt', 'IMG_20200329_142525.jpg', 'IMG_20200329_142525.txt', 'IMG_20200329_142530.jpg', 'IMG_20200329_142530.txt', 'IMG_20200329_142535.jpg', 'IMG_20200329_142535.txt', 'IMG_20200329_142542.jpg', 'IMG_20200329_142542.txt', 'IMG_20200329_142558.jpg', 'IMG_20200329_142558.txt', 'IMG_20200329_142612.jpg', 'IMG_20200329_142612.txt', 'IMG_20200329_142615.jpg', 'IMG_20200329_142615.txt', 'IMG_20200329_142619(1).jpg', 'IMG_20200329_142619(1).txt', 'IMG_20200329_142619.jpg', 'IMG_20200329_142619.txt', 'IMG_20200329_142626.jpg', 'IMG_20200329_142626.txt', 'IMG_20200329_142649.jpg', 'IMG_20200329_142649.txt', 'IMG_20200329_142653.jpg', 'IMG_20200329_142653.txt', 'IMG_20200329_142656.jpg', 'IMG_20200329_142656.txt', 'IMG_20200329_142704.jpg', 'IMG_20200329_142704.txt', 'IMG_20200329_142707.jpg', 'IMG_20200329_142707.txt', 'IMG_20200329_142718.jpg', 'IMG_20200329_142718.txt', 'IMG_20200329_142727.jpg', 'IMG_20200329_142727.txt', 'IMG_20200329_142734.jpg', 'IMG_20200329_142734.txt', 'IMG_20200329_142737.jpg', 'IMG_20200329_142737.txt', 'IMG_20200329_142740.jpg', 'IMG_20200329_142740.txt', 'IMG_20200329_142745.jpg', 'IMG_20200329_142745.txt', 'IMG_20200329_142751.jpg', 'IMG_20200329_142751.txt', 'IMG_20200329_142759.jpg', 'IMG_20200329_142759.txt', 'IMG_20200329_152619.jpg', 'IMG_20200329_152619.txt', 'IMG_20200329_152622.jpg', 'IMG_20200329_152622.txt', 'IMG_20200329_152625.jpg', 'IMG_20200329_152625.txt', 'IMG_20200329_152635.jpg', 'IMG_20200329_152635.txt', 'IMG_20200329_152638.jpg', 'IMG_20200329_152638.txt', 'IMG_20200329_152642.jpg', 'IMG_20200329_152642.txt', 'IMG_20200329_152649.jpg', 'IMG_20200329_152649.txt', 'IMG_20200329_152654.jpg', 'IMG_20200329_152654.txt', 'IMG_20200329_152659.jpg', 'IMG_20200329_152659.txt', 'IMG_20200329_152704.jpg', 'IMG_20200329_152704.txt', 'IMG_20200329_152708.jpg', 'IMG_20200329_152708.txt', 'IMG_20200329_152720.jpg', 'IMG_20200329_152720.txt', 'IMG_20200329_152730.jpg', 'IMG_20200329_152730.txt', 'IMG_20200329_152734.jpg', 'IMG_20200329_152734.txt', 'IMG_20200329_152735.jpg', 'IMG_20200329_152735.txt', 'IMG_20200329_152741.jpg', 'IMG_20200329_152741.txt', 'IMG_20200329_152746.jpg', 'IMG_20200329_152746.txt', 'IMG_20200329_152752.jpg', 'IMG_20200329_152752.txt', 'IMG_20200329_152755.jpg', 'IMG_20200329_152755.txt', 'IMG_20200329_152800.jpg', 'IMG_20200329_152800.txt', 'IMG_20200329_152804.jpg', 'IMG_20200329_152804.txt', 'IMG_20200329_152836.jpg', 'IMG_20200329_152836.txt', 'IMG_20200329_152840(1).jpg', 'IMG_20200329_152840(1).txt', 'IMG_20200329_152844.jpg', 'IMG_20200329_152844.txt', 'IMG_20200329_152857.jpg', 'IMG_20200329_152857.txt', 'IMG_20200329_152858.jpg', 'IMG_20200329_152858.txt', 'IMG_20200329_201009.jpg', 'IMG_20200329_201009.txt', 'IMG_20200329_201011.jpg', 'IMG_20200329_201011.txt', 'IMG_20200329_201015.jpg', 'IMG_20200329_201015.txt', 'IMG_20200329_201018.jpg', 'IMG_20200329_201018.txt', 'IMG_20200329_201042.jpg', 'IMG_20200329_201042.txt', 'IMG_20200329_201047.jpg', 'IMG_20200329_201047.txt', 'IMG_20200329_201049.jpg', 'IMG_20200329_201049.txt', 'IMG_20200329_201051.jpg', 'IMG_20200329_201051.txt', 'IMG_20200329_201109.jpg', 'IMG_20200329_201109.txt', 'IMG_20200329_201113.jpg', 'IMG_20200329_201113.txt', 'IMG_20200329_201125.jpg', 'IMG_20200329_201125.txt', 'IMG_20200329_201129.jpg', 'IMG_20200329_201129.txt', 'IMG_20200329_201131.jpg', 'IMG_20200329_201131.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = r\"C:\\Users\\medhi\\e_waste\\flask-project\\archive(3)\\data\"\n",
        "\n",
        "if os.path.exists(dataset_path):\n",
        "    print(\"‚úÖ Dataset found:\", os.listdir(dataset_path))\n",
        "else:\n",
        "    print(\"‚ùå Dataset not found! Check the path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset organized successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "organized_path = \"organized_dataset\"\n",
        "\n",
        "# Create organized dataset folder\n",
        "os.makedirs(organized_path, exist_ok=True)\n",
        "\n",
        "# Process each text file\n",
        "for file in os.listdir(dataset_path):\n",
        "    if file.endswith(\".txt\"):\n",
        "        txt_path = os.path.join(dataset_path, file)\n",
        "        image_name = file.replace(\".txt\", \".jpeg\")  # Assuming .jpeg format\n",
        "        image_path = os.path.join(dataset_path, image_name)\n",
        "\n",
        "        # Read the first line from the .txt file to get the class label\n",
        "        with open(txt_path, \"r\") as f:\n",
        "            first_line = f.readline().strip()\n",
        "            if first_line:\n",
        "                class_label = first_line.split(\" \")[0]  # Extract class number\n",
        "                \n",
        "                # Create class folder\n",
        "                class_folder = os.path.join(organized_path, class_label)\n",
        "                os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "                # Move image to respective class folder\n",
        "                if os.path.exists(image_path):\n",
        "                    shutil.move(image_path, os.path.join(class_folder, image_name))\n",
        "\n",
        "print(\"‚úÖ Dataset organized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 352 files belonging to 6 classes.\n",
            "‚úÖ Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    organized_path,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Dataset loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9pat7qngWZX7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset organized successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "output_path = \"organized_dataset\"\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "for file in os.listdir(dataset_path):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
        "        label = file.split(\"_\")[0]  # Modify this based on your naming convention\n",
        "        class_folder = os.path.join(output_path, label)\n",
        "\n",
        "        if not os.path.exists(class_folder):\n",
        "            os.makedirs(class_folder)\n",
        "\n",
        "        shutil.move(os.path.join(dataset_path, file), os.path.join(class_folder, file))\n",
        "\n",
        "print(\"‚úÖ Dataset organized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJXgbJx_Wcwj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqR1lBhVWimu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/content/dataset/organized_data\"\n",
        "print(\"üìÇ Folders inside dataset:\", os.listdir(dataset_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f256_5fQWvox"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_path = \"/content/dataset\"\n",
        "organized_path = \"/content/dataset/organized_data\"\n",
        "\n",
        "os.makedirs(organized_path, exist_ok=True)\n",
        "\n",
        "for file in os.listdir(dataset_path):\n",
        "    if file.endswith(\".jpeg\") or file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        class_name = file.split(\"_\")[0]  # Modify this based on your naming pattern\n",
        "        class_folder = os.path.join(organized_path, class_name)\n",
        "        os.makedirs(class_folder, exist_ok=True)\n",
        "        shutil.move(os.path.join(dataset_path, file), os.path.join(class_folder, file))\n",
        "\n",
        "print(\"‚úÖ Dataset organized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6yunyO6Wxgp"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/dataset/organized_data\",\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8g-QJh87XAFp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÇ TRAIN SET:\n",
            "   Battery: 240 images\n",
            "   Keyboard: 240 images\n",
            "   Microwave: 240 images\n",
            "   Mobile: 240 images\n",
            "   Mouse: 240 images\n",
            "   PCB: 240 images\n",
            "   Player: 240 images\n",
            "   Printer: 240 images\n",
            "   Television: 240 images\n",
            "   Washing Machine: 240 images\n",
            "\n",
            "üìÇ TEST SET:\n",
            "   Battery: 30 images\n",
            "   Keyboard: 30 images\n",
            "   Microwave: 30 images\n",
            "   Mobile: 30 images\n",
            "   Mouse: 30 images\n",
            "   PCB: 30 images\n",
            "   Player: 30 images\n",
            "   Printer: 30 images\n",
            "   Television: 30 images\n",
            "   Washing Machine: 30 images\n",
            "\n",
            "üìÇ VAL SET:\n",
            "   Battery: 30 images\n",
            "   Keyboard: 30 images\n",
            "   Microwave: 30 images\n",
            "   Mobile: 30 images\n",
            "   Mouse: 30 images\n",
            "   PCB: 30 images\n",
            "   Player: 30 images\n",
            "   Printer: 30 images\n",
            "   Television: 30 images\n",
            "   Washing Machine: 30 images\n",
            "\n",
            "üìå TRAIN: 0 classes have less than 5 images.\n",
            "\n",
            "üìå TEST: 0 classes have less than 5 images.\n",
            "\n",
            "üìå VAL: 0 classes have less than 5 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "splits = [\"train\", \"test\", \"val\"]  # Define dataset splits\n",
        "\n",
        "# Dictionary to store image counts per class in each split\n",
        "split_class_counts = {split: {} for split in splits}\n",
        "\n",
        "# Loop through train, test, val directories\n",
        "for split in splits:\n",
        "    split_path = os.path.join(dataset_path, split)  # e.g., /content/dataset/organized_data/train\n",
        "    \n",
        "    if not os.path.exists(split_path):\n",
        "        print(f\"‚ö†Ô∏è Warning: {split} folder not found!\")\n",
        "        continue  # Skip if folder doesn't exist\n",
        "    \n",
        "    # Loop through each class inside the split (e.g., keyboard, mouse, pcb)\n",
        "    for cls in os.listdir(split_path):\n",
        "        class_folder = os.path.join(split_path, cls)\n",
        "        \n",
        "        # Ensure it's a folder before counting\n",
        "        if os.path.isdir(class_folder):\n",
        "            # Count only image files inside the class folder\n",
        "            image_count = len([f for f in os.listdir(class_folder) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            split_class_counts[split][cls] = image_count\n",
        "\n",
        "# Print class-wise image count for each split\n",
        "for split, class_counts in split_class_counts.items():\n",
        "    print(f\"\\nüìÇ {split.upper()} SET:\")\n",
        "    for cls, count in class_counts.items():\n",
        "        print(f\"   {cls}: {count} images\")\n",
        "\n",
        "# Count classes with very few images in each split\n",
        "for split, class_counts in split_class_counts.items():\n",
        "    few_images = sum(1 for count in class_counts.values() if count < 5)\n",
        "    print(f\"\\nüìå {split.upper()}: {few_images} classes have less than 5 images.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ghpZJVeea0CA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "image_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for ext in image_extensions:\n",
        "        if fnmatch.filter(files, ext):\n",
        "            print(f\"‚úÖ Found images in: {root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiY2Z8gFa-oL"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/dataset/organized_data\",  # ‚úÖ Correct path\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/dataset/organized_data\",  # ‚úÖ Correct path\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clUABtJ7bGsk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/content/dataset/organized_data\"\n",
        "print(\"üìÇ Contents of organized_data:\", os.listdir(dataset_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GkHlGwSwbTFT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  file_name     label\n",
            "0    1.jpeg  keyboard\n",
            "1   10.jpeg  keyboard\n",
            "2   11.jpeg  keyboard\n",
            "3   12.jpeg  keyboard\n",
            "4   13.jpeg  keyboard\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = \"dataset_labels.csv\"  # Adjust if needed\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(df.head())  # Show the first few rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9PFrCDHebfCg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Images organized into class folders successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "csv_path = \"dataset_labels.csv\"  # Path to CSV file\n",
        "image_source_path = \"organized_dataset\"  # Folder containing subfolders with images\n",
        "output_path = \"sorted_data\"  # Where to organize images\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to find the actual image path inside nested folders\n",
        "def find_image(image_name, search_path):\n",
        "    for root, _, files in os.walk(search_path):\n",
        "        if image_name in files:  # Check if the image exists in any subfolder\n",
        "            return os.path.join(root, image_name)\n",
        "    return None  # Return None if image is not found\n",
        "\n",
        "# Organize images into class folders\n",
        "for _, row in df.iterrows():\n",
        "    filename = row[\"file_name\"]  # Ensure column names match CSV\n",
        "    label = row[\"label\"]  # Class label\n",
        "\n",
        "    # Find the actual image location in the subfolders\n",
        "    src = find_image(filename, image_source_path)\n",
        "\n",
        "    if src:  # If image exists\n",
        "        dest_dir = os.path.join(output_path, label)  # Class folder\n",
        "        dest = os.path.join(dest_dir, filename)\n",
        "\n",
        "        # Create class folder if it doesn't exist\n",
        "        os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "        # Move image\n",
        "        shutil.move(src, dest)\n",
        "\n",
        "print(\"‚úÖ Images organized into class folders successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FOAnbCMObjdD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 39 classes.\n",
            "Found 0 images belonging to 39 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"sorted_data\",  # ‚úÖ Now points to the correct folder\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    \"sorted_data\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OddNftIlbrTW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Class Distribution: {'bottle': 103, 'bottle bottle': 48, 'bottle bottle bottle': 30, 'keyboard': 5, 'laptop': 16, 'laptop laptop': 25, 'laptop laptop mobile mobile': 3, 'laptop mobile mobile': 8, 'laptop mouse': 3, 'mobile': 45, 'mobile mobile': 12, 'mobile mobile laptop': 7, 'mobile mobile laptop laptop': 2, 'monitor': 7, 'mouse': 10, 'mouse laptop': 3}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"sorted_data\"\n",
        "\n",
        "# Count images per class\n",
        "class_counts = {cls: len(os.listdir(os.path.join(dataset_path, cls))) for cls in os.listdir(dataset_path)}\n",
        "print(\"üìä Class Distribution:\", class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gnm-GwbFcB5r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Merged: bottle bottle ‚ûù bottle\n",
            "‚úÖ Merged: bottle bottle bottle ‚ûù bottle\n",
            "‚úÖ Merged: laptop laptop ‚ûù laptop\n",
            "‚úÖ Renamed: laptop laptop mobile mobile ‚ûù laptop_mobile\n",
            "‚úÖ Merged: laptop mobile mobile ‚ûù laptop_mobile\n",
            "‚úÖ Renamed: laptop mouse ‚ûù laptop_mouse\n",
            "‚úÖ Merged: mobile mobile ‚ûù mobile\n",
            "‚úÖ Merged: mobile mobile laptop ‚ûù laptop_mobile\n",
            "‚úÖ Merged: mobile mobile laptop laptop ‚ûù laptop_mobile\n",
            "‚úÖ Merged: mouse laptop ‚ûù laptop_mouse\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_path = \"sorted_data\"\n",
        "\n",
        "# Function to clean class names\n",
        "def clean_class_names(class_name):\n",
        "    return \"_\".join(set(class_name.split()))  # Removes duplicates & uses underscores\n",
        "\n",
        "# Iterate through dataset and rename folders\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    new_name = clean_class_names(class_folder)\n",
        "    old_path = os.path.join(dataset_path, class_folder)\n",
        "    new_path = os.path.join(dataset_path, new_name)\n",
        "\n",
        "    if old_path != new_path:\n",
        "        if os.path.exists(new_path):  # If the new folder already exists, merge files\n",
        "            for file_name in os.listdir(old_path):\n",
        "                shutil.move(os.path.join(old_path, file_name), new_path)\n",
        "            os.rmdir(old_path)  # Remove the empty folder\n",
        "            print(f\"‚úÖ Merged: {class_folder} ‚ûù {new_name}\")\n",
        "        else:\n",
        "            os.rename(old_path, new_path)\n",
        "            print(f\"‚úÖ Renamed: {class_folder} ‚ûù {new_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T_hFO4JtcKaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ bottle: 181 images\n",
            "üìÇ keyboard: 5 images\n",
            "üìÇ laptop: 41 images\n",
            "üìÇ laptop_mobile: 20 images\n",
            "üìÇ laptop_mouse: 6 images\n",
            "üìÇ mobile: 57 images\n",
            "üìÇ monitor: 7 images\n",
            "üìÇ mouse: 10 images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"sorted_data\"\n",
        "\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wr8gc7-RcSyE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóëÔ∏è Removed empty class: bottle\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "empty_class = \"sorted_data/bottle\"\n",
        "if os.path.exists(empty_class):\n",
        "    shutil.rmtree(empty_class)\n",
        "    print(f\"üóëÔ∏è Removed empty class: bottle\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "E05wHzadciKt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "def augment_images(folder_path, num_augmentations=5):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "        # Check if the item is a file before processing\n",
        "        if os.path.isfile(img_path):  # Only process files, not directories\n",
        "            img = load_img(img_path)\n",
        "            img_array = img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path, save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "minority_classes = [\"mobile_mouse\", \"monitor_mouse\", \"mobile_laptop\"]\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=10)\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "l-kV-CQPcmzz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ keyboard: 5 images\n",
            "üìÇ laptop: 41 images\n",
            "üìÇ laptop_mobile: 20 images\n",
            "üìÇ laptop_mouse: 6 images\n",
            "üìÇ mobile: 57 images\n",
            "üìÇ monitor: 7 images\n",
            "üìÇ mouse: 10 images\n"
          ]
        }
      ],
      "source": [
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIRlGYwBcwBZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Define augmentation parameters\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to augment images\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")\n",
        "\n",
        "# List of minority classes to augment\n",
        "minority_classes = [\"mobile_mouse\", \"monitor_mouse\", \"mobile_laptop\", \"laptop_mouse\"]\n",
        "\n",
        "# Apply augmentation\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"/content/dataset/sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=10)  # Generate 10x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0O0Pf3Xc1VM"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/dataset/sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz2AJD6pdCpf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Define augmentation parameters\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to augment images\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")\n",
        "\n",
        "# List of minority classes to augment\n",
        "minority_classes = [\"mobile_mouse\", \"monitor_mouse\", \"mobile_laptop\", \"laptop_mouse\"]\n",
        "\n",
        "# Apply augmentation\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"/content/dataset/sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=10)  # Generate 10x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mfoKzX8dFEU"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/dataset/sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "weI4rzKFdQ2t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Augmented images for: laptop_mouse\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Define image augmentation parameters\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to augment images in a folder\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")\n",
        "\n",
        "# List of minority classes to augment\n",
        "minority_classes = [\"mobile_mouse\", \"laptop_mouse\", \"monitor_keyboard\", \"monitor_mouse\", \"mobile_laptop\"]\n",
        "\n",
        "# Apply augmentation\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=10)  # Generate 10x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "E19LBsa1dTGC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ keyboard: 5 images\n",
            "üìÇ laptop: 41 images\n",
            "üìÇ laptop_mobile: 20 images\n",
            "üìÇ laptop_mouse: 66 images\n",
            "üìÇ mobile: 57 images\n",
            "üìÇ monitor: 7 images\n",
            "üìÇ mouse: 10 images\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RkhCQcEddKs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Define augmentation parameters\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to augment images in a folder\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")\n",
        "\n",
        "# List of minority classes to augment\n",
        "minority_classes = [\"mobile_mouse\", \"laptop_mouse\", \"monitor_keyboard\", \"monitor_mouse\", \"mobile_laptop\"]\n",
        "\n",
        "# Apply augmentation\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"/content/dataset/sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=10)  # Generate 10x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7MWuv6jde5M"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/dataset/sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZiLwVo0SdpdW"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorted_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder):\n\u001b[1;32m---> 43\u001b[0m     \u001b[43maugment_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Generate 10x images per class\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Augmented images for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[4], line 27\u001b[0m, in \u001b[0;36maugment_images\u001b[1;34m(folder_path, num_augmentations)\u001b[0m\n\u001b[0;32m     24\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Expand dims\u001b[39;00m\n\u001b[0;32m     26\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maugmentor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:654\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    652\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n\u001b[0;32m    653\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 654\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n\u001b[0;32m    658\u001b[0m batch_x[i] \u001b[38;5;241m=\u001b[39m x\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1413\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   1410\u001b[0m img_col_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1411\u001b[0m img_channel_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1413\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_row_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_col_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m     x \u001b[38;5;241m=\u001b[39m apply_channel_shift(\n\u001b[0;32m   1431\u001b[0m         x,\n\u001b[0;32m   1432\u001b[0m         transform_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1433\u001b[0m         img_channel_axis,\n\u001b[0;32m   1434\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1880\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   1876\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1877\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1879\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1880\u001b[0m     \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m   1889\u001b[0m ]\n\u001b[0;32m   1890\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1891\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\ndimage\\_interpolation.py:628\u001b[0m, in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    625\u001b[0m     _nd_image\u001b[38;5;241m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[38;5;241m/\u001b[39mmatrix, output, order,\n\u001b[0;32m    626\u001b[0m                          mode, cval, npad, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 628\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometric_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Define augmentation parameters\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to augment images in a folder\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")\n",
        "\n",
        "# List of minority classes to augment\n",
        "minority_classes = ['laptop_mobile']\n",
        "\n",
        "# Apply augmentation\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=2)  # Generate 10x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WWh6mOevdseP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ keyboard: 848 images\n",
            "üìÇ laptop: 832 images\n",
            "üìÇ laptop_mobile: 573 images\n",
            "üìÇ laptop_mouse: 1219 images\n",
            "üìÇ mobile: 744 images\n",
            "üìÇ monitor: 600 images\n",
            "üìÇ mouse: 673 images\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvbfflT3d7r3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Define augmentation parameters\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to augment images in a folder\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")\n",
        "\n",
        "# List of minority classes (less than 50 images)\n",
        "minority_classes = [\"mobile\", \"laptop_mobile\",'keyboard','monitor','mouse']\n",
        "\n",
        "# Apply augmentation\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=10)  # Generate 10x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-Ihi6k-d_Ki"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nw8OUeYeWjJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "y80qY2epeYBI"
      },
      "outputs": [],
      "source": [
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,      # Randomly rotate images by up to 30 degrees\n",
        "    width_shift_range=0.2,   # Randomly shift images horizontally by up to 20% of the width\n",
        "    height_shift_range=0.2,  # Randomly shift images vertically by up to 20% of the height\n",
        "    shear_range=0.2,        # Randomly apply shearing transformations\n",
        "    zoom_range=0.2,         # Randomly zoom in or out on images\n",
        "    horizontal_flip=True,   # Randomly flip images horizontally\n",
        "    fill_mode=\"nearest\"     # Fill any empty pixels with the nearest value\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "suUP_YnKedXU"
      },
      "outputs": [],
      "source": [
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mbotoXIegiI"
      },
      "outputs": [],
      "source": [
        "# Define minority classes\n",
        "minority_classes = [\"mobile_mouse\", \"laptop_mouse\", \"monitor_keyboard\", \"monitor_mouse\", \"mobile_laptop\"]\n",
        "\n",
        "# Augment images in minority classes\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"/content/dataset/sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=10)  # Increase the number of images by 10x\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IzIrpU2eekuq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ keyboard: 5 images\n",
            "üìÇ laptop: 41 images\n",
            "üìÇ laptop_mobile: 20 images\n",
            "üìÇ laptop_mouse: 66 images\n",
            "üìÇ mobile: 57 images\n",
            "üìÇ monitor: 7 images\n",
            "üìÇ mouse: 10 images\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aLm_4Vyet6f"
      },
      "outputs": [],
      "source": [
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=45,  # Increased rotation range\n",
        "    width_shift_range=0.3,  # Increased width shift range\n",
        "    height_shift_range=0.3,  # Increased height shift range\n",
        "    shear_range=0.3,  # Increased shear range\n",
        "    zoom_range=0.3,  # Increased zoom range\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsnwnRczevls"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIjMLqGpexxC"
      },
      "outputs": [],
      "source": [
        "def augment_images(folder_path, num_augmentations=20):  # Increased augmentations\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)\n",
        "            img_array = img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXA96rnIezSI"
      },
      "outputs": [],
      "source": [
        "# Define minority classes\n",
        "minority_classes = [\"mobile_mouse\", \"laptop_mouse\", \"monitor_keyboard\", \"monitor_mouse\", \"mobile_laptop\"]\n",
        "\n",
        "# Augment images in minority classes\n",
        "for class_name in minority_classes:\n",
        "    folder = f\"/content/dataset/sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=20)  # Generate 20x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjKFxAdTe4PK"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/dataset/sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2WoX1dSfDLC"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/dataset/sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ORi50-pJfGkk"
      },
      "outputs": [],
      "source": [
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],  # Adjust brightness\n",
        "    channel_shift_range=20,  # Adjust color channels\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hr3itmqJfLyC"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[39], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorted_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder):\n\u001b[1;32m---> 12\u001b[0m     \u001b[43maugment_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Augmented images for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[32], line 29\u001b[0m, in \u001b[0;36maugment_images\u001b[1;34m(folder_path, num_augmentations)\u001b[0m\n\u001b[0;32m     26\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Expand dims\u001b[39;00m\n\u001b[0;32m     28\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maugmentor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:654\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    652\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n\u001b[0;32m    653\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 654\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n\u001b[0;32m    658\u001b[0m batch_x[i] \u001b[38;5;241m=\u001b[39m x\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1430\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   1413\u001b[0m x \u001b[38;5;241m=\u001b[39m apply_affine_transform(\n\u001b[0;32m   1414\u001b[0m     x,\n\u001b[0;32m   1415\u001b[0m     transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1426\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation_order,\n\u001b[0;32m   1427\u001b[0m )\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1430\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mapply_channel_shift\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchannel_shift_intensity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflip_horizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1437\u001b[0m     x \u001b[38;5;241m=\u001b[39m flip_axis(x, img_col_axis)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1685\u001b[0m, in \u001b[0;36mapply_channel_shift\u001b[1;34m(x, intensity, channel_axis)\u001b[0m\n\u001b[0;32m   1682\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, channel_axis, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1683\u001b[0m min_x, max_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(x), np\u001b[38;5;241m.\u001b[39mmax(x)\n\u001b[0;32m   1684\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1685\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mintensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_x\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m   1686\u001b[0m ]\n\u001b[0;32m   1687\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1688\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2341\u001b[0m, in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out, min, max, **kwargs)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmax\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[0;32m   2338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `min` or `max` keyword argument when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2339\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:117\u001b[0m, in \u001b[0;36m_clip\u001b[1;34m(a, min, max, out, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m um\u001b[38;5;241m.\u001b[39mmaximum(a, \u001b[38;5;28mmin\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "minority_classes = {\n",
        "    \"mobile_mouse\": 50,  # Augment 50x\n",
        "    \"laptop_mouse\": 30,  # Augment 30x\n",
        "    \"monitor_keyboard\": 20,  # Augment 20x\n",
        "    \"monitor_mouse\": 30,  # Augment 30x\n",
        "    \"mobile_laptop\": 40  # Augment 40x\n",
        "}\n",
        "\n",
        "for class_name, num_augmentations in minority_classes.items():\n",
        "    folder = f\"sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=num_augmentations)\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NYk2eHGgfRmg"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: '/content/dataset/sorted_data'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/dataset/sorted_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      3\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, class_folder)\n\u001b[0;32m      4\u001b[0m     num_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(folder_path))\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/dataset/sorted_data'"
          ]
        }
      ],
      "source": [
        "dataset_path = \"/content/dataset/sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-0hGflsvfaT7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorted_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder):\n\u001b[1;32m---> 51\u001b[0m     \u001b[43maugment_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Generate 10x images per class\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Augmented images for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[32], line 29\u001b[0m, in \u001b[0;36maugment_images\u001b[1;34m(folder_path, num_augmentations)\u001b[0m\n\u001b[0;32m     26\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Expand dims\u001b[39;00m\n\u001b[0;32m     28\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maugmentor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:654\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    652\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n\u001b[0;32m    653\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 654\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n\u001b[0;32m    658\u001b[0m batch_x[i] \u001b[38;5;241m=\u001b[39m x\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1413\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   1410\u001b[0m img_col_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1411\u001b[0m img_channel_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1413\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_row_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_col_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m     x \u001b[38;5;241m=\u001b[39m apply_channel_shift(\n\u001b[0;32m   1431\u001b[0m         x,\n\u001b[0;32m   1432\u001b[0m         transform_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1433\u001b[0m         img_channel_axis,\n\u001b[0;32m   1434\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1880\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   1876\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1877\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1879\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1880\u001b[0m     \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m   1889\u001b[0m ]\n\u001b[0;32m   1890\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1891\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\ndimage\\_interpolation.py:628\u001b[0m, in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    625\u001b[0m     _nd_image\u001b[38;5;241m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[38;5;241m/\u001b[39mmatrix, output, order,\n\u001b[0;32m    626\u001b[0m                          mode, cval, npad, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 628\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometric_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Define image augmentation parameters\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],  # Adjust brightness\n",
        "    channel_shift_range=20,  # Adjust color channels\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to augment images in a folder\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # Load image\n",
        "            img_array = img_to_array(img)  # Convert to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Expand dims\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")\n",
        "\n",
        "# Define minority classes and the desired number of augmentations per class\n",
        "minority_classes = {\n",
        "    \"mobile_mouse\": 500,\n",
        "    \"laptop_mouse\": 300,\n",
        "    \"monitor_keyboard\": 200,\n",
        "    \"monitor_mouse\": 300,\n",
        "    \"mobile_laptop\": 400\n",
        "}\n",
        "\n",
        "# Apply augmentation\n",
        "for class_name, num_augmentations in minority_classes.items():\n",
        "    folder = f\"sorted_data/{class_name}\"\n",
        "    if os.path.exists(folder):\n",
        "        augment_images(folder, num_augmentations=num_augmentations)  # Generate 10x images per class\n",
        "        print(f\"‚úÖ Augmented images for: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ODq2kI8fgZl"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/dataset/sorted_data\"\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N4VBtmo5fqy4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ keyboard: 848 images\n",
            "üìÇ laptop: 832 images\n",
            "üìÇ laptop_mobile: 573 images\n",
            "üìÇ laptop_mouse: 1219 images\n",
            "üìÇ mobile: 744 images\n",
            "üìÇ monitor: 600 images\n",
            "üìÇ mouse: 673 images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def count_images(directory):\n",
        "    \"\"\"Counts the number of images in a directory, considering subdirectories.\"\"\"\n",
        "    total_count = 0\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                total_count += 1\n",
        "    return total_count\n",
        "\n",
        "# Path to your dataset\n",
        "dataset_path = \"sorted_data\"\n",
        "\n",
        "# Create an ImageDataGenerator (no augmentation needed for counting)\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "# Get the class subdirectories\n",
        "class_folders = os.listdir(dataset_path)\n",
        "\n",
        "# Count images in each class\n",
        "for class_folder in class_folders:\n",
        "    class_path = os.path.join(dataset_path, class_folder)\n",
        "    num_images = count_images(class_path)  # Use custom function to count\n",
        "    print(f\"üìÇ {class_folder}: {num_images} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UMggx7Dbf0QD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np  # Corrected indentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import time\n",
        "\n",
        "def augment_images(folder_path, num_augmentations=10):\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)\n",
        "            img_array = img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            i = 0\n",
        "            for batch in augmentor.flow(img_array, batch_size=1, save_to_dir=folder_path,\n",
        "                                        save_prefix=f\"aug_{int(time.time())}_{i}\", save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= num_augmentations:\n",
        "                    break  # Generate only `num_augmentations` images per original image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {img_file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5oGIHbddgJ-K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4395 images belonging to 7 classes.\n",
            "Found 1094 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = 128  # Adjust to your image size\n",
        "BATCH_SIZE = 32  # Adjust to your batch size\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 20% for validation\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"sorted_data\",  # Your augmented dataset path\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    \"sorted_data\",\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZF2IkADIgrqf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ keyboard: 848 images\n",
            "üìÇ laptop: 832 images\n",
            "üìÇ laptop_mobile: 218 images\n",
            "üìÇ laptop_mouse: 1219 images\n",
            "üìÇ mobile: 744 images\n",
            "üìÇ monitor: 600 images\n",
            "üìÇ mouse: 110 images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"sorted_data\"\n",
        "\n",
        "for class_folder in sorted(os.listdir(dataset_path)):\n",
        "    folder_path = os.path.join(dataset_path, class_folder)\n",
        "    num_files = len(os.listdir(folder_path))\n",
        "    print(f\"üìÇ {class_folder}: {num_files} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i-6YanS1gbHL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 3s/step - accuracy: 0.4554 - loss: 1.5823 - val_accuracy: 0.8805 - val_loss: 0.5199\n",
            "Epoch 2/10\n",
            "\u001b[1m  1/137\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m18s\u001b[0m 133ms/step - accuracy: 0.7812 - loss: 0.3452"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m137/137\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 580ms/step - accuracy: 0.7812 - loss: 0.3452 - val_accuracy: 0.8603 - val_loss: 0.6249\n",
            "Epoch 3/10\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 3s/step - accuracy: 0.9088 - loss: 0.2863 - val_accuracy: 0.9246 - val_loss: 0.4248\n",
            "Epoch 4/10\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 571ms/step - accuracy: 0.8750 - loss: 0.3302 - val_accuracy: 0.9237 - val_loss: 0.4789\n",
            "Epoch 5/10\n",
            "\u001b[1m 25/137\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m4:46\u001b[0m 3s/step - accuracy: 0.9532 - loss: 0.1523"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust as needed\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(7, activation='softmax')  # 12 output classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=10,  # Adjust as needed\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YZr-e1UMhirb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Train-Test Split Completed!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "dataset_path = \"sorted_data\"\n",
        "train_dir = \"sorted_data/train\"\n",
        "test_dir = \"sorted_data/test\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Split each class (with a minimum of 2 images)\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_folder)\n",
        "    images = os.listdir(class_path)\n",
        "\n",
        "    # Check if the class has at least 2 images for splitting\n",
        "    if len(images) >= 2:  # Skip classes with fewer than 2 images\n",
        "        train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Create class folders in train/test directories\n",
        "        os.makedirs(os.path.join(train_dir, class_folder), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_folder), exist_ok=True)\n",
        "\n",
        "        # Move images\n",
        "        for img in train_images:\n",
        "            shutil.move(os.path.join(class_path, img), os.path.join(train_dir, class_folder, img))\n",
        "        for img in test_images:\n",
        "            shutil.move(os.path.join(class_path, img), os.path.join(test_dir, class_folder, img))\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping class '{class_folder}' with fewer than 2 images.\")\n",
        "\n",
        "print(\"‚úÖ Train-Test Split Completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RN1AfKZDhoJ-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4007 images belonging to 6 classes.\n",
            "Found 763 images belonging to 5 classes.\n",
            "‚úÖ Data Preprocessing Completed!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Paths\n",
        "train_dir = \"sorted_data/train/train\"\n",
        "test_dir = \"sorted_data/train/train/test\"\n",
        "\n",
        "# Data Augmentation & Normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load Images in Batches\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data Preprocessing Completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXpLoloohtQy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Prevent overfitting\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"‚úÖ CNN Model Ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmgfah7piDGI"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"‚úÖ Model Accuracy: {test_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU8oq7nqif2I"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(256, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qpay2YQiGKh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Load Pretrained Model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# Add Custom Layers\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riwyPYRAime5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jaW3C-wUiyO5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load Pretrained MobileNetV2\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base layers\n",
        "\n",
        "# Add Custom Layers\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')  # Adjust based on class count\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xLC8EaeJjBVQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3364 images belonging to 6 classes.\n",
            "Found 933 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for validation\n",
        "\n",
        "# Replace with the actual paths to your training and validation data\n",
        "train_generator = train_datagen.flow_from_directory('sorted_data/train/train', target_size=(224,224), batch_size=32, class_mode='categorical')\n",
        "val_generator = val_datagen.flow_from_directory('sorted_data/test', target_size=(224,224), batch_size=32, class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "itNCs0WDjCv3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 3s/step - accuracy: 0.9002 - loss: 0.3892 - val_accuracy: 0.9528 - val_loss: 0.1313\n",
            "Epoch 2/20\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - accuracy: 0.9725 - loss: 0.1000 - val_accuracy: 0.9925 - val_loss: 0.0424\n",
            "Epoch 3/20\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 3s/step - accuracy: 0.9733 - loss: 0.0852 - val_accuracy: 0.9968 - val_loss: 0.0166\n",
            "Epoch 4/20\n",
            "\u001b[1m  9/106\u001b[0m \u001b[32m‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m3:35\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0352"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\medhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator, validation_data=val_generator, epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTDchk2cjIQN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GrO-5G2WmxHm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.9940 - loss: 0.0167\n",
            "Validation Accuracy: 0.9946\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqFHG_LKnHg6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `history` is the object returned from model.fit()\n",
        "def plot_accuracy_loss(history):\n",
        "    # Plot Accuracy\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Model Accuracy')\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Model Loss')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_accuracy_loss(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "56hok06loYxB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# After training your model (in previous code cells)\n",
        "model.save('your_model.h5')  # Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bGI-MkJfobqI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model using the correct path\n",
        "model = tf.keras.models.load_model(\"your_model.h5\")\n",
        "\n",
        "# ... rest of the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NDrvM5tIodrS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\medhi\\AppData\\Local\\Temp\\tmpix55o8or\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\medhi\\AppData\\Local\\Temp\\tmpix55o8or\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\medhi\\AppData\\Local\\Temp\\tmpix55o8or'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_2')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2020809326032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997832464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997833424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997832848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997833040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997834576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997834960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997835344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997835152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997830160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997836496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997836880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997837264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997837072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997831888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997838416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997838800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997839184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997838992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997834192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997840336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997833232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997840720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997840528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2020997838032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000021392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000021776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000022160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000021968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000020048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000023312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000023696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000024080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000023888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000020240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000025232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000025616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000026000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000025808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000020816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000027152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000027536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000027920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000027728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000022928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000029072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000029456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000029840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000029648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000024848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000030992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000031376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000031760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000031568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000026768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000032912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000033296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000033680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000033488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000028688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000034832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000035216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000035984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000035408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000030608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000034064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000168464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000167504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000034448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000167696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000169808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000170192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000170576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000170384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000167888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000171728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000172112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000172496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000172304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000168272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000173648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000174032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000174416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000174224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000169424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000175568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000175952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000176336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000176144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000171344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000177488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000177872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000178256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000178064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000173264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000179408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000179792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000180176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000179984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000175184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000181328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000181712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000182096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000181904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000177104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000183248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000168656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000183632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000183440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021000180944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004296656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004298000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004298384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004298192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004296848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004299536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004299920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004300304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004300112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004297424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004301456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004301840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004302224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004302032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004297616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004303376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004303760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004304144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004303952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004299152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004305296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004305680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004306064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004305872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004301072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004307216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004307600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004307984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004307792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004302992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004309136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004309520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004309904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004309712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004304912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004311056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004311440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004312208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004311632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004306832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004310288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004476496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004477648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004310672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004477456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004478800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004479184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004479568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004479376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004477264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004480720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004481104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004481488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004481296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004476688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004482640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004483024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004483408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004483216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004478416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004484560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004484944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004485328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004485136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004480336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004486480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004486864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004487248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004487056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004482256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004488400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004488784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004489168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004488976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004484176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004490320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004490704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004491088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004490896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004486096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004492240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004476880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004492624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004492432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004489936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004674448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004674832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004675216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004675024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004673872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004676368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004676752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004677136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004676944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004673296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004678288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004678672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004679056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004678864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004673104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004680208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004680592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004680976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004680784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004675984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004682128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004682512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004682896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004682704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004677904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004684048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004684432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004684816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004684624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004679824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004685968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004686352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004686736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004686544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004681744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004687888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004688272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004689040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004688464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004683664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004687120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004837520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004838096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004687504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004837136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004839248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004839632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004840016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004839824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004836944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004841168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004841552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004841936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004841744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004837712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004843088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004843472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004843856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004843664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004838864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004845008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004845392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004845776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004845584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004840784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004846928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004847696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004846160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2021004849040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "‚úÖ Model successfully converted to TFLite and saved as 'model.tflite'.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"your_model.h5\")  # Replace with your model's path\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Optimize for size and speed\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"‚úÖ Model successfully converted to TFLite and saved as 'model.tflite'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCYPbMKComNG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Prepare a test sample (reshape it to match model input)\n",
        "test_sample = np.random.rand(1, 224, 224, 3).astype(np.float32)  # Modify shape accordingly\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], test_sample)\n",
        "\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get prediction\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"TFLite Model Output:\", output_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZZwrrdNTWOV"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to a file\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssi5nR0YTdh0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('model.tflite')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
